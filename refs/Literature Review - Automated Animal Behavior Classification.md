# Automated Animal Behavior Classification

## Survey of Machine Learning Methods and Biologging Applications

## 1. Introduction

The use of miniaturized electronic sensors attached to free-ranging animals (biologging) has revolutionized how ecologists study animal behavior, physiology, and interactions with the environment ([Whitford, M., et al., 2019](https://doi.org/10.1186/s40317-019-0189-z)). Modern biologging tags often include Inertial Measurement Units (IMUs) with accelerometers, gyroscopes, and magnetometers that can record hundreds of data points per second. These high-resolution motion sensors allow researchers to reconstruct an animal’s activities even when direct observation is impossible (e.g. marine animals deep underwater or nocturnal species) ([Chung et al., 2021](https://doi.org/10.1007/s12601-021-00015-1)). Initially, a major challenge was simply collecting and retrieving these data from tags. As technology improved (smaller, cheaper, and more reliable tags), the new bottleneck became data interpretation – making sense of the massive datasets each tag produces. Manually annotating hours or weeks of sensor data is impractical when each sensor can yield millions of data points. This challenge has driven the widespread adoption of automated classification methods, especially machine learning (ML) and, more recently, deep learning (DL), to infer behaviors from raw biologging data ([Bergen et al., 2022](https://doi.org/10.1111/2041-210X.14019)).

Early biologging studies often took a *post hoc* approach: tags were retrieved and data analyzed after the fact. Today, there is a growing interest in real-time, on-animal processing to classify behaviors as they happen, enabling immediate insights and more efficient data handling. This review examines the state of the art in animal behavior classification from biologger data, with an emphasis on marine species (where observational challenges are extreme). We compare traditional post hoc analysis to emerging on-tag (real‑time) classification, and we extend the discussion to applications in farm, pet, and zoo animal monitoring. Throughout, we highlight key algorithms and approaches, recent developments, and future directions such as energy‑efficient “TinyML” models and integrative data frameworks.

## 2. Behavioral Classification in Marine Animals

Marine environments pose exceptional challenges for observing animal behavior – many species spend most of their time underwater or far from humans, making direct observation difficult or impossible ([Chung et al., 2021](https://doi.org/10.1007/s12601-021-00015-1)). Biologging has therefore been transformative in marine biology. Tags on sharks, whales, seals, fish, and seabirds have revealed details of migration routes, foraging dives, and social behaviors that were previously hidden. Below we review how behavior classification is performed with marine biologging data.

### 2.1 Feature Engineering and Signal Processing

Before behavioral classification can occur, raw sensor data must be processed and transformed into meaningful features that capture the biomechanical and kinematic properties of animal movement. This feature engineering step is foundational to all classification approaches, whether traditional machine learning or deep learning, and significantly impacts model performance and interpretability.

#### 2.1.1 Static vs Dynamic Acceleration Components

Raw accelerometer data contains both static and dynamic components that must be separated to extract meaningful behavioral information ([Shepard et al., 2008](https://doi.org/10.3354/esr00084)). **Static acceleration** represents the orientation of the animal relative to Earth's gravitational field, providing information about posture and body angle. **Dynamic acceleration** captures the animal's movement patterns and is derived by subtracting the static component from total acceleration.

Static acceleration is typically computed using smoothing techniques such as running means over 1-2 seconds ([Shepard et al., 2008](https://doi.org/10.3354/esr00084)) or low-pass filtering ([Chakravarty et al., 2019](https://doi.org/10.1111/2041-210X.13172)). Body pitch and roll angles can then be calculated using the arcsine of static acceleration values, with different axes showing varying sensitivity to angular changes depending on animal orientation. These postural metrics are particularly valuable for distinguishing behaviors like vigilance vs. resting in terrestrial mammals, or identifying dive phases in aquatic species.

#### 2.1.2 Dynamic Body Acceleration Metrics

Two primary approaches exist for quantifying overall dynamic body acceleration from tri-axial data. **Overall Dynamic Body Acceleration (ODBA)** sums the absolute values from three orthogonal axes, while **Vectorial Dynamic Body Acceleration (VeDBA)** calculates the vector magnitude ([Qasem et al., 2012](https://doi.org/10.1371/journal.pone.0031187)). Although VeDBA might seem theoretically superior as a true vectorial measure, research comparing these metrics found ODBA performed slightly better as a proxy for energy expenditure across multiple species. This suggests that simultaneous contraction of stabilizing muscles during movement may be better captured by summing components rather than vectorial calculation. Both metrics serve as proxies for energy expenditure and activity intensity, forming the basis for many behavioral classification features.

#### 2.1.3 Frequency Domain Features

Spectral analysis reveals the periodic structure of movement patterns, enabling discrimination between rhythmic locomotion and aperiodic behaviors like foraging ([Chakravarty et al., 2019](https://doi.org/10.1111/2041-210X.13172)). **Fast Fourier Transform (FFT)** analysis identifies dominant frequencies and power spectral density, with periodic locomotion showing clear peaks at characteristic stride frequencies, while irregular behaviors like foraging exhibit relatively flat spectra. [Brewster et al., 2021](https://doi.org/10.3390/s21196392) achieved 95.9% accuracy classifying nine behavioral classes using 1D CNNs operating on FFT features, demonstrating the power of frequency domain representations for complex behavior recognition.

#### 2.1.4 Statistical and Morphological Features

Time-domain statistical features capture the distributional properties of acceleration signals within analysis windows. Commonly used metrics include mean, variance, standard deviation, skewness, kurtosis, and percentiles computed across each axis ([Dunford et al., 2024](https://doi.org/10.1002/ece3.11380)). **Standard error** or **running standard deviation** measures have proven particularly valuable, providing consistent measures of movement amplitude that distinguish high-energy from low-energy behaviors ([Dunford et al., 2024](https://doi.org/10.1002/ece3.11380)).

Morphological features describe signal shape characteristics including peak detection and amplitude patterns ([Garde et al., 2022](https://doi.org/10.1111/2041-210X.13804)). Peak detection algorithms are particularly valuable for extracting wingbeat frequency from acceleration data, where peaks in the dynamic heave acceleration can identify individual wingbeat cycles and their duration ([Garde et al., 2022](https://doi.org/10.1111/2041-210X.13804)). These features are especially useful for identifying specific movement signatures such as tail beats in fish ([Leos-Barajas et al., 2017](https://doi.org/10.1111/2041-210X.12657)) or wingbeat patterns in birds ([Garde et al., 2022](https://doi.org/10.1111/2041-210X.13804)). The combination of statistical and morphological features provides complementary information about both the intensity and structure of movement patterns.

#### 2.1.5 Window Size and Temporal Considerations

The choice of analysis window size significantly impacts feature quality and classification performance ([Dunford et al., 2024](https://doi.org/10.1002/ece3.11380)). Window sizes must balance temporal resolution with behavioral context - shorter windows (0.5-2 seconds) capture fine-scale movement details but may lack behavioral context, while longer windows (5-10 seconds) provide behavioral coherence but may smooth important details.

**Sampling frequency** considerations show that higher frequencies (≥40 Hz) excel at identifying fast-paced behaviors like running or rapid wingbeats, while lower frequencies (1-5 Hz) or averaged data better capture slower, aperiodic behaviors such as grooming and feeding ([Dunford et al., 2024](https://doi.org/10.1002/ece3.11380)). This frequency-behavior matching suggests that multi-scale approaches using different temporal resolutions for different behavioral categories may optimize overall classification performance.

**Class imbalance** in behavioral datasets poses significant challenges, with common behaviors like resting often dominating datasets (>70%) while behaviorally important activities like feeding may represent <2% of data ([Agarwal et al., 2024](https://doi.org/10.1101/2024.12.28.630628)). Feature engineering must account for this through standardized duration sampling, where abundant behaviors are subsampled to create more balanced training sets ([Dunford et al., 2024](https://doi.org/10.1002/ece3.11380)).

### 2.2 Post‑Hoc Classification Methods

Building upon the feature engineering foundation, post‑hoc classification involves applying machine learning algorithms to processed accelerometer features. In the standard post‑hoc workflow, researchers recover the tag (or remotely download its memory), then apply classification algorithms on a computer. This batch analysis yields a behavioral time‑series after the deployment is over. Key steps include calibrating sensors, segmenting the data into time windows, extracting features, and using a trained model to assign behavior labels ([Leos-Barajas et al., 2016](https://doi.org/10.1111/2041-210X.12657)).

#### 2.2.1 Supervised Machine Learning

Most animal behavior classification to date has used supervised ML, which requires a labeled dataset for training. Typically, researchers collect video or direct observations simultaneously with sensor data to "ground‑truth" the IMU signals ([Garde et al., 2022](https://doi.org/10.1111/2041-210X.13804)). Characteristic signal patterns (e.g. acceleration or rotation profiles) are thus tagged with the corresponding behavior (e.g. swimming, resting, feeding), providing training examples. Once a model learns these mappings, it can predict behaviors from new sensor data.

**Data Quality and Calibration Challenges.** However, the reliability of behavior classification depends critically on sensor calibration and standardized protocols. [Garde et al., 2022](https://doi.org/10.1111/2041-210X.13804) conducted a comprehensive review revealing that only 5% of accelerometer-based studies mention calibration protocols, despite calibration errors causing up to 5% measurement inaccuracies in dynamic body acceleration (DBA). They found that tag placement alone can introduce 9-25% variation in measurements, emphasizing the need for standardized attachment protocols. These methodological inconsistencies can propagate through machine learning pipelines, potentially compromising classification accuracy and ecological inference. Their work highlights the importance of careful sensor calibration and standardized data collection protocols as prerequisites for reliable automated behavior classification.

Common supervised algorithms include:

- **Random Forest (RF):** An ensemble of decision trees that is robust to noise and high‑dimensional data. RF has been used widely, from aquatic animals (e.g. differentiating seal behaviors) to domestic species ([Ladds et al., 2016](https://doi.org/10.1371/journal.pone.0166898)). Its performance is often strong across a range of behaviors, and it can handle many input features without overfitting. The ensemble approach makes it inherently robust to outliers and noisy sensor readings common in biologging data.

- **Support Vector Machines (SVM):** A classifier that finds the optimal hyperplane to separate classes. SVMs have achieved high accuracy in various cases like classifying rodent gaits and cattle activities ([Rahman et al., 2018](https://doi.org/10.1016/j.inpa.2017.10.001)). They can work well with a proper kernel choice, though they may require careful parameter tuning and are less interpretable than tree-based methods. SVMs are particularly effective when dealing with high-dimensional feature spaces common in biologging applications.

- **k‑Nearest Neighbors (k‑NN):** A simple approach that assigns a behavior based on the majority vote of the k most similar data points in the training set. k‑NN can perform adequately for distinguishing broad behavior classes and was even favored over RF in one eagle study for fine-grained flight modes ([Bergen et al., 2022](https://doi.org/10.1111/2041-210X.14019)), although its simplicity can be a drawback with very large datasets due to computational costs during inference.

- **Gradient Boosted Trees (e.g., XGBoost):** Boosting methods build an ensemble of sequentially improved trees and often outperform other classifiers on structured data. XGBoost in particular has shown excellent accuracy and scalability. For example, ([Bergen et al., 2022](https://doi.org/10.1111/2041-210X.14019)) reviewed multiple studies using XGBoost for behavior classification, noting its superior performance and computational efficiency compared to RF and SVM when handling large datasets. Notably, XGBoost handled the "big data" size better (faster runtime) than RF or SVM in that case. Given its performance and efficiency, XGBoost is increasingly recommended when millions of observations need classification.

It is important to note that no single algorithm is best for all applications. Model performance can vary by species and behavior complexity. For instance, in a comparative study on Atlantic goliath grouper fish, an RF model slightly outperformed an SVM, and each had specific behaviors they classified well ([Brewster et al., 2021](https://doi.org/10.3390/s21196392)). This underscores the value of testing multiple algorithms and feature sets for a given problem. Overall, supervised ML has enabled automated ethograms (behavior catalogs) with high accuracy in many settings, significantly reducing the need for manual scoring.

#### 2.2.2 Deep Learning

In recent years, deep learning approaches have gained popularity for behavior classification. **Deep Neural Networks** can automatically learn complex features from raw sensor inputs, alleviating the need for manual feature engineering. This is a key advantage over traditional ML, which typically requires computed summary statistics (means, variances, spectra, etc.) as inputs.

The most common DL architectures are:

- **Convolutional Neural Networks (CNNs):** which can extract local patterns (e.g. movement signatures) from multivariate time series. CNNs have been applied to animal IMU data with great success ([Brewster et al., 2021](https://doi.org/10.3390/s21196392)). In the goliath grouper study mentioned above, a 1D CNN operating on Fast Fourier Transform (FFT) features achieved 95.9% overall sensitivity in classifying nine behavioral classes, outperforming both RF (94.2%) and SVM (93.3%) ([Brewster et al., 2021](https://doi.org/10.3390/s21196392)). CNNs are powerful for recognizing repetitive motifs like tail beats or strides. They have even been used to estimate animal pose from images, which can feed into detecting specific behaviors from video ([Arac et al., 2019](https://doi.org/10.3389/fnsys.2019.00020)).

- **Recurrent Neural Networks (RNNs):** especially those with Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU) cells, which are designed to capture temporal dependencies. RNN-based models can naturally model the time sequence of behavior data ([Wang, L., et al., 2023](https://doi.org/10.1016/j.compag.2023.107647)). Studies have found that LSTM networks can improve classification of movement bouts by remembering context (e.g. distinguishing similar motions like trotting vs. galloping by sequence). GRUs, being a simpler variant, often perform similarly to LSTMs with less computational cost. Wang et al. (2023) identified a single-layer GRU with 64 hidden units as optimal, achieving 95.2% accuracy for cattle behavior classification while maintaining computational efficiency suitable for embedded deployment.

- **Hybrid CNN‑RNN models:** which combine convolutional layers (to learn spatial or short-term features) with recurrent layers (to capture longer-term sequences). Such architectures have shown promise in human activity recognition and are being explored for animals ([Arac et al., 2019](https://doi.org/10.3389/fnsys.2019.00020)). For example, a model combining a 3-layer CNN with an LSTM improved performance in one benchmark, benefiting from both detailed feature extraction and sequence learning. Another study combined CNN-derived features with classical statistical features to classify dog behaviors, achieving over 95% accuracy in a diverse activity set.

**Temporal Smoothing and Post-processing.** Raw model predictions often exhibit temporal noise, with rapid switching between predicted behaviors that is biologically implausible. [Dunford et al. (2024)](https://doi.org/10.1002/ece3.11380) demonstrated methodological improvements for behavior classification accuracy from accelerometer data. Additionally, several studies have applied hidden Markov model smoothing to enforce realistic behavior transitions and reduce misclassification of brief transitional movements ([Leos-Barajas et al., 2016](https://doi.org/10.1111/2041-210X.12657)).

Deep learning can thus achieve state-of-the-art accuracy. However, it comes with higher computational requirements and often needs large labeled datasets for training.

**Class Imbalance Challenges.** A critical issue in behavior classification is the natural imbalance in behavioral frequencies. [Agarwal et al., 2024](https://doi.org/10.1101/2024.12.28.630628) documented that feeding behaviors represented only 0.49-1.46% of data in seabird studies and 7.59% in arctic foxes, while resting often dominates datasets (>70%). This imbalance can bias models toward overrepresented behaviors. Solutions include flexible rebalancing techniques, where a parameter θ adjusts class weights during training, and synthetic data augmentation for rare behaviors. Recent work also emphasizes the importance of reporting per-class metrics (precision, recall) rather than just overall accuracy to reveal model performance on minority behaviors.

**Species Distribution and Transfer Learning.** Interestingly, while DL is now routine in human wearable data analysis, it has been sparsely applied in animal behavior studies until recently. This is changing as researchers curate bigger animal datasets (including community shared datasets) and leverage transfer learning or data augmentation to overcome limited labels. For instance, pretraining a network on human or other animal data and fine-tuning it on a target species can boost performance when labels are scarce.

**Uncertainty Estimation and Anomaly Detection:** As models become more sophisticated, it's important they also communicate their confidence ([Agarwal et al., 2024](https://doi.org/10.1101/2024.12.28.630628)). Wilson et al. (2025) provide comprehensive validation guidelines, recommending: (1) leave-one-individual-out cross-validation to test generalization, (2) temporal blocking to avoid data leakage from autocorrelation, (3) reporting confusion matrices and per-class F1 scores, and (4) testing on completely independent datasets when possible. Recent work emphasizes classifying behaviors with uncertainty measures, so that researchers know when to trust the model's predictions.

**Self-Supervised Learning.** Beyond supervised methods, [Fazzari et al., 2024](https://doi.org/10.48550/arXiv.2405.14002) highlight emerging self-supervised approaches like Selfee ([Jia et al., 2022](https://doi.org/10.7554/eLife.76218)), which uses Siamese neural networks to extract discriminative features directly from raw video without labels, representing a promising direction for reducing annotation burden.

**Multi-animal Monitoring.** Recent advances in computer vision have enabled simultaneous monitoring of multiple individuals, revealing social dynamics like dominance hierarchies and synchronized behaviors that individual tags miss. Combining individual biologgers with group-level video analysis provides a more complete behavioral picture. [Fazzari et al., 2024](https://doi.org/10.48550/arXiv.2405.14002) note that publicly available datasets for collective and social behavior prediction remain limited primarily to mice and fish, despite the computational advances in multi-animal tracking. They highlight MARS ([Segalin et al., 2021](https://doi.org/10.7554/eLife.63720)) and CS-IGANet ([Zhou et al., 2022](https://doi.org/10.48550/arXiv.2208.03819)) as key frameworks for social interaction analysis in freely interacting animals.

**Unsupervised and Semi‑Supervised Methods.** While most work uses supervised learning, there is growing interest in methods that do not require exhaustive manual labeling. Unsupervised clustering or **hidden Markov models (HMMs)** can segment behavioral modes based on statistical properties of movement data, and have been used to identify states like "encamped vs traveling" in animal tracks ([Leos-Barajas et al., 2016](https://doi.org/10.1111/2041-210X.12657)). For example, an HMM approach by Leos-Barajas et al. (2016) classified animal movement behavior by identifying distinct states in space-use and movement-speed data. These data-driven approaches can reveal patterns that human observers might overlook, though interpreting the clusters or states in ethological terms can be challenging. Increasingly, researchers are also exploring semi-supervised techniques that combine a small amount of labeled data with a large amount of unlabeled data to improve classifier robustness. This can significantly reduce the annotation effort required while still producing accurate models.

### 2.3 On‑Tag Streaming Classification vs. Post‑Hoc Analysis

Traditional post‑hoc analysis has two major limitations in biologging: (a) Tag recovery is often required to get the data, which is infeasible for many marine animals (tags may be lost or unattainable once the animal leaves); and (b) recording and transmitting high‑resolution raw data is energy and memory intensive ([Garde et al., 2022](https://doi.org/10.1111/2041-210X.13804)). Next‑generation tags address these issues by performing **on‑board classification** — i.e. processing data on the tag in real time and transmitting or storing only the distilled behavior information.

In an on-tag classification paradigm, the tag's microprocessor runs a lightweight algorithm continuously. Instead of sending raw accelerometer or gyroscope readings, the device might transmit messages like "dive start," "gliding," "foraging buzz," etc., or simply log these behaviors internally with timestamps. This approach offers several advantages:

**Dramatically Reduced Data Volume and Energy Use:** Transmitting a simple behavior label (a few bytes) uses far less bandwidth than streaming raw sensor traces ([Yu, H., et al. (2021)](https://doi.org/10.1186/s40462-021-00245-x)). On-board processing can significantly reduce battery consumption and memory usage compared to transmitting raw accelerometer data. These savings mean tags can either last much longer on the same battery or collect higher-resolution data within practical memory limits. Essentially, on-board processing allows longer deployments and more data collected per unit power.

**Real‑Time Monitoring and Alerts:** With satellite or acoustic telemetry, on-tag classification enables near-real-time data flow ([Beltran, R. S. (2024)](https://doi.org/10.1016/j.tree.2024.09.009)). Researchers and wildlife managers can receive immediate updates on critical events (e.g. an animal entering a dangerous area or exhibiting unusual behavior). This is valuable for conservation – for instance, tags could potentially alert park rangers if a protected animal is being chased (poaching risk) or to detect illegal fishing activity by recognizing stress behaviors in tagged marine fauna. Real-time insight also allows adaptive tracking (e.g. deciding to recover a tag when certain behaviors are observed).

**No Tag Recovery Needed for Data:** On-board analysis can circumvent the need to physically recover the device in some cases. If key results are transmitted (even at low bandwidth), scientists can collect behavioral data from animals that are never recaptured – a huge benefit for species that are hard to find or for one-time deployments like disposable satellite tags. This approach has been likened to "the Internet of Animals", where thousands of tagged animals send streams of behavioral data to a global database in real time (facilitated by satellite networks and projects like ICARUS). Such a network can vastly expand the scale of ecological monitoring.

Of course, implementing on-tag classification is challenging. The computational constraints on tags are severe: embedded processors have limited clock speed, memory, and power (running on battery). Complex models like large deep neural networks typically cannot be deployed directly on tiny hardware without modifications ([Brewster et al., 2021](https://doi.org/10.3390/s21196392); [Wilson et al., 2025](https://doi.org/10.1111/1365-2656.70054)). If a model is too slow or power-hungry, it could negate the battery savings of on-board processing. One practical limitation noted by Brewster et al. (2021) is that deep learning algorithms might require a larger battery (thus a physically larger tag) to run continuously, which is "not practical for many species" due to drag or attachment concerns. Therefore, researchers are actively developing resource-efficient algorithms and model compression techniques for edge devices.

Some promising strategies include:

**Designing shallow or optimized neural networks** that approximate the performance of complex models but with far fewer computations ([Wang, L., et al. (2023)](https://doi.org/10.1016/j.compag.2023.107647)). For example, specialized filter banks or convolutional kernels can be hand-crafted to detect key signal features (like tail beat frequency) rather than learning dozens of layers of representation. These act somewhat like simplified CNN/RNN hybrids tuned for low power use.

**Using TinyML approaches** – training a full-sized model on the cloud or offline, then distilling it into a smaller model or even directly into efficient code for the microcontroller. Techniques such as knowledge distillation (where a small network learns to mimic a large network's predictions) and quantization (using lower-precision arithmetic) can significantly shrink model size and execution cost. One field deployment on cattle demonstrated in situ classification using a deep neural network on a collar tag, successfully recognizing behaviors with minimal latency ([Arablouei et al., 2023](https://doi.org/10.1016/j.compag.2023.107707)). The deployment used an ARM Cortex-M3 processor with limited computational resources (28 KB RAM, 128 KB ROM), demonstrating that real-time behavior classification is feasible on resource-constrained embedded systems. [Fazzari et al., 2024](https://doi.org/10.48550/arXiv.2405.14002) emphasize that storage limitations and computational demands remain critical challenges for on-device deployment, with techniques like Quantized-CNN attempting to balance robust detection with efficient compression. They note that achieving this balance without compromising precision remains a crucial consideration for reliable behavioral analyses.

**Choosing model architectures naturally suited for low-power chips.** The GRU-based model mentioned earlier is a good example – it achieved accuracy comparable to deeper networks but is simpler to compute ([Wang, L., et al., 2023](https://doi.org/10.1016/j.compag.2023.107647)). In that study, the single-layer GRU could run on a modest microcontroller, making real-time cattle behavior monitoring feasible. Similarly, decision-tree ensembles like XGBoost, if limited in tree depth, can be efficient to evaluate and were run on custom sheep collars for real-time posture classification in a prior experiment ([Bergen et al., 2022](https://doi.org/10.1111/2041-210X.14019)).

In summary, on-board behavior classification is rapidly advancing from concept to reality. It marries the rich detail of biologging with the efficiency of event-driven data collection. The likely future is a hybrid approach: high-frequency raw data might be stored intermittently or when interesting events are detected, while summary behavioral information is continuously transmitted. This would extend battery life and provide real-time insights without sacrificing data resolution. Overcoming the remaining technical hurdles will involve collaboration between ecologists, engineers, and computer scientists to ensure models are not just accurate, but also computationally feasible in the wild.

## 3. Expansion to Other Animal Domains

### 3.1 Livestock and Farm Animals

In modern precision livestock farming, sensors help monitor animal health, productivity, and welfare continuously. Accelerometer-based behavior classification has been especially useful for cattle, sheep, and goats ([Rahman et al., 2018](https://doi.org/10.1016/j.inpa.2017.10.001); [Cesarani et al., 2021](https://doi.org/10.3390/ani11030724)).

For **dairy cattle** and **beef cattle**, researchers have developed collar, halter, and ear-tag devices that automatically classify behaviors such as grazing, ruminating (chewing cud), resting (lying down), and walking. These behaviors are key indicators: for example, reduced rumination or excess rest can signal illness or distress. By tracking activity patterns, systems can predict important events in advance. Studies have shown that changes in motion and posture can foretell calving (parturition) up to 24 hours before it occurs. Accelerometer data, sometimes combined with temperature or other sensors, are used to detect when cows enter estrus (heat) – which is critical for timely breeding – with much higher accuracy than visual observation. Farmers also use behavior data to identify lameness (lameness alters gait and lying time) and to ensure cows are feeding properly. Supervised ML models like SVM and RF have been trained on cattle accelerometer datasets with high success (often >90% accuracy for the core behaviors).

One active area is deploying real-time alert systems in pastures. Researchers have tested solar-powered collars that send SMS alerts when a cow shows signs of birthing or unusual inactivity. In New Zealand, on-animal classification has even been used to detect when cattle are in oestrus by recognizing increased walking activity and restlessness, allowing ranchers to optimize breeding timing. Early trials of on-board ML for cattle (such as the work of Arablouei and colleagues) demonstrated that edge computing on a herd is feasible – in a 2022 field trial, behavior classification was performed directly on cow collars in situ, freeing the system from constant raw data transmission ([Arablouei et al., 2023](https://doi.org/10.1109/JSEN.2022.3186598)).

Similar approaches extend to **small ruminants**. Accelerometers on sheep and goats can distinguish activities like grazing (head-down moderate motion), sleeping or lying, and traveling. This helps in extensive rangeland management – e.g., ensuring flocks are actively grazing in intended areas or detecting predator disturbances (sudden intense movement). Models for sheep behavior have achieved good accuracy with simple algorithms, and on-tag classification has been tested on sheep with custom hardware ([Bergen et al., 2022](https://doi.org/10.1111/2041-210X.14019)). Knowing when and where livestock graze versus rest also informs pasture use and can improve rotational grazing strategies.

**Bioacoustics and Sensor Fusion.** Fazzari et al. (2024) note that bioacoustics research in behavior classification remains surprisingly limited, with most work focusing on species identification and sound event detection rather than behavior analysis. They highlight that [Wang, K. et al. (2021)](https://doi.org/10.1016/j.compag.2021.106275) pioneered sheep behavior classification using log-scaled Mel-spectrograms with CNNs, achieving success in distinguishing chewing, biting, and ruminating sounds. Fazzari et al. (2024) emphasize that sensor fusion with advanced architectures incorporating fusion layers has been shown to mitigate noise and enhance precision of analysis, particularly when combining accelerometers, gyroscopes, and GNSS data.

Overall, automated behavior monitoring in farms leads to earlier detection of problems (like a cow going off-feed due to illness) and labor savings. As one review put it, farm animals today are far removed from natural behaviors due to selective breeding and housing, so continuous monitoring is key to identifying welfare issues ([Cesarani et al., 2021](https://doi.org/10.3390/ani11030724)). The combination of biologgers with machine learning provides a kind of "virtual herder" that watches over each animal individually. In the coming years, integration of accelerometer data with other inputs (rumen pH, GPS position, milk yield sensors, etc.) will enable even richer classification of states like heat stress, pain, or specific diseases (which often manifest in subtle behavior changes).

### 3.2 Companion and Zoo Animals

**Pets (Companion Animals):** Pet owners and veterinarians are increasingly using wearable sensors to keep an eye on animal activity and wellness. For example, accelerometer-based "smart collars" for dogs and cats can log how much time the pet spends walking, running, sleeping, or playing ([Ketrzynska, D., 2023](https://stud.epsilon.slu.se/19548/1/Ketrzynska_Daria_231009.pdf)). This information helps owners ensure their pet is getting enough exercise and rest. Research in this domain focuses on optimizing sensor placement (neck vs. harness vs. collar) and developing models that work across different breeds and sizes. One study improved dog activity classification by refining the sampling frequency and window length used for analysis. Another experiment combined a CNN with traditional features to distinguish dog behaviors like sitting, standing, running, and eating, achieving high accuracy (in some cases over 95%).

Commercial pet fitness trackers already classify basic activities and even alert owners to anomalies (for instance, if a dog's sleep is restless or it shows signs of scratching more than usual, which could indicate skin irritation). In cats, activity monitors help detect low activity levels that might signify arthritis pain or other health issues. As these devices become more sophisticated, they may incorporate ML models to recognize specific patterns such as "cat is hunting" versus "cat is grooming," etc., and could notify owners of potential stress or behavioral problems.

**Zoo and Captive Wildlife:** Biologging and ML are being used to monitor animal welfare in zoos and aquariums in unobtrusive ways ([Arac et al., 2019](https://doi.org/10.3389/fnsys.2019.00020)), ([Wang, R., et al., 2023](http://dx.doi.org/10.18494/SAM4521)). One application is detecting stereotypic behaviors – repetitive, invariant actions like pacing or swaying that can indicate stress or poor welfare in captive animals. Traditionally, zookeepers would observe and manually record such behaviors. Now, camera systems with deep learning algorithms can do this automatically. For example, a recent study implemented an automated video analysis framework for polar bears in a zoo, using deep learning to track the bears' locations and walking paths continuously. This system could identify when a bear was pacing back and forth in a corner (a common stereotypy) and quantify its frequency and duration. By localizing individuals and analyzing their movement trajectories, the framework provided objective data on how much time each bear spent pacing versus engaged in normal activities. Such data can alert zookeepers to welfare concerns and help evaluate if interventions (like environmental enrichment) are effective. Beyond pacing, similar computer vision approaches have been used to monitor social interactions, enclosure usage (which areas an animal frequents), and even feeding behavior in zoo animals.

Wearable sensors can also be applied in zoos. Accelerometer collars have been trialed on animals like captive elephants to assess walking distances and activity budgets, aiding in exercise planning. In one case, tri-axial accelerometers on zoo elephants helped distinguish between standing, walking, and lying down with high accuracy, which was useful for monitoring obesity and joint health. Another pilot project fitted great apes with wrist trackers to detect abnormal inactivity or excessive regurgitation behavior, providing early warnings to caretakers. As with wildlife, the challenge is making devices that are animal-proof and comfortable, but the potential benefits for proactive healthcare in zoos are significant.

Overall, whether it's a dairy cow, a pet dog, or a zoo polar bear, the combination of biologging telemetry and behavior classification algorithms is opening new frontiers in animal care. These technologies allow us to quantitatively "listen" to animals' behavior patterns and respond to their needs more promptly. They also generate large datasets that can be mined for insights into animal biology and psychology. For instance, aggregating pet activity data from thousands of homes could reveal how household factors influence animal behavior, and zoo sensor data could help identify subtle signs of stress across species. The cross-pollination of methods between wildlife ecology and animal husbandry domains is accelerating – a technique pioneered to classify wild bird flight might be repurposed to monitor free-range chickens, and vice versa.

## 4. Conclusion and Future Directions

Animal behavior classification via biologging has rapidly evolved in the past decade. We have moved from manual annotation of sensor traces to an array of sophisticated ML and DL techniques that can automatically infer behaviors with high accuracy. In marine research, these methods have unveiled hidden lives of creatures from sharks to seals, while in agricultural and captive settings they are improving animal welfare and management. *Post hoc* analysis using powerful models (CNNs, XGBoost, etc.) often provides the highest accuracies, but the field is increasingly recognizing the practical limits of such approaches in terms of data volume and field logistics. This is driving a new paradigm of edge computing in biologging – performing classification on the tag or "at the edge" to enable real-time, scalable monitoring.

Looking ahead, several key trends and research directions are likely to shape this field:

**TinyML and Efficient Models:** There is a strong push toward developing algorithms that can run on minimal hardware ([Arablouei et al., 2023](https://doi.org/10.1016/j.compag.2023.107707)). Techniques like model compression, quantization, and one-shot learning will be important. Future tags might include specialized AI chips (similar to those in smartphones) optimized for running neural networks with very low power. Achieving deep learning on a coin-cell-powered device is a grand challenge – one that, when solved, will unlock fully autonomous tags that analyze complex behaviors (perhaps even new behaviors) on the fly. Early successes with GRU-based models on collars and knowledge-distillation approaches for cow behavior are promising steps in this direction.

**Multisensor Data Fusion:** Thus far, many studies focus on accelerometer data alone, but animals are being equipped with a suite of sensors – GPS for location, magnetometers for heading, gyroscopes for orientation, pressure sensors for depth/altitude, microphones for sound, even physiological sensors (heart rate, temperature) ([Bergen et al., 2022](https://doi.org/10.1111/2041-210X.14019); [Whitford, M., et al., 2019](https://doi.org/10.1186/s40317-019-0189-z)). Merging these data streams can greatly improve classification and provide context (e.g. distinguishing running vs. swimming if you have both accelerometer and depth data). Future classification models will likely incorporate environmental features too: for example, linking an animal's behavior with weather or habitat data. This is already seen in studies like Hooten et al. (2018) where environmental variables (wind speed, time of day, etc.) were used alongside movement data to classify eagle behaviors. Integrating multiple modalities could enable a more holistic understanding of animal state – not just "what behavior is this?" but "why is the animal doing this now?".

**Uncertainty Estimation and Anomaly Detection:** As models become more sophisticated, it's important they also communicate their confidence ([Agarwal et al., 2025](https://doi.org/10.1101/2024.12.28.630628)). [Wilson et al., 2025](https://doi.org/10.1111/1365-2656.70054) provide comprehensive validation guidelines, recommending: (1) leave-one-individual-out cross-validation to test generalization, (2) temporal blocking to avoid data leakage from autocorrelation, (3) reporting confusion matrices and per-class F1 scores, and (4) testing on completely independent datasets when possible. Recent work emphasizes classifying behaviors with uncertainty measures, so that researchers know when to trust the predictions. Along with this, unsupervised techniques can identify novel or anomalous behavior patterns that were not part of the training set – essentially letting the animals tell us when they do something unexpected. These could lead to new biological discoveries (for instance, an animal performing a never-before-seen behavior might be automatically flagged for human review).

**Explainable AI in Behavior Analysis.** [Fazzari et al., 2024](https://doi.org/10.48550/arXiv.2405.14002) identify explainable AI as an underexplored area, with only [Choi et al., 2022](https://doi.org/10.48550/arXiv.2108.09394) using Grad-CAM to understand neural network decisions in ant swarm behavior analysis. This represents a significant gap given the importance of understanding model decisions in ethological research.

**Reinforcement Learning Integration.** [Fazzari et al., 2024](https://doi.org/10.48550/arXiv.2405.14002) identify reinforcement learning as a critical unexplored frontier, enabling not just behavior detection but understanding of decision-making processes and behavioral adaptation. They envision creating "digital twins" and interactive simulacra of animal behavior, similar to advances in human behavior studies, allowing researchers to simulate how animals adapt in diverse environments.

**Scalability and the "Internet of Animals":** With cheaper, smarter tags and global data networks, we are approaching an era where thousands to millions of animals of various species could be concurrently monitored ([Beltran, R. S., 2024](https://doi.org/10.1016/j.tree.2024.09.009)). Initiatives like the ICARUS project (International Cooperation for Animal Research Using Space) have already launched infrastructure to track wildlife via the International Space Station. The next step is to have those animals not just be tracked, but also reporting their behaviors in real time. This will create an immense, live dataset of the planet's animal movements and activities. If made open-access, such data could transform ecology and conservation – enabling continent-scale analyses of animal responses to climate change, human disturbance, and more. Achieving this will require common data standards and collaboration across disciplines (the "Animal Internet" will be as much a software challenge as a hardware one). But the payoff would be unprecedented: a dynamic map of global biodiversity in motion.

**Ethical and Welfare Considerations:** As biologging expands, ensuring the welfare of tagged animals remains paramount ([Holton et al., 2021](https://doi.org/10.1098/rstb.2020.0229); [Cesarani et al., 2021](https://doi.org/10.3390/ani11030724)). Lighter, more efficient tags reduce the burden on animals. Also, real-time classification can be used to trigger compassionate interventions – for example, if a tagged animal is injured or in distress, an alert could prompt researchers to attempt a rescue or medical care (this is particularly relevant for endangered species or animals under human care). Privacy and data ethics also extend to animals; discussions are emerging about data ownership and ensuring biologging data is used to benefit conservation and not inadvertently aid poachers or other threats.

In conclusion, biologger telemetry combined with advanced classification algorithms has opened a new window into animal behavior. We can now "see" what animals are doing 24/7, across landscapes and seascapes, with minimal human observation bias. The continuing convergence of ecology, machine learning, and sensor engineering is making these systems more autonomous, intelligent, and integrative. By focusing on energy efficiency, multi-sensor fusion, and large-scale frameworks, researchers are paving the way for a future where we monitor ecosystems through the collective behaviors of their animal inhabitants. This not only deepens our scientific understanding but can guide effective conservation action in a rapidly changing world. The ultimate vision is a planet-wide network of animals as sentinels – each one a source of insight into the rhythms of life on Earth

---

## References

- [Agarwal, M., et al. (2025)](https://doi.org/10.1101/2024.12.28.630628). Leveraging machine learning and accelerometry to classify animal behaviours with uncertainty. *bioRxiv preprint*.
- [Ahokas, J. (2024)](https://liu.diva-portal.org/smash/record.jsf?pid=diva2%3A1883347). Automated animal behavior analysis using accelerometer activity tags. *Master’s thesis, Linköping University, Department of Electrical Engineering*.
- [Anupam, S. (2024)](http://dx.doi.org/10.13140/RG.2.2.18872.97284). Animal behavior detection using extra‑trees algorithm and accelerometer data. *preprint*.
- [Arablouei, R., et al. (2023)](https://doi.org/10.1016/j.compag.2023.107707). Animal behavior classification via deep learning on embedded systems. *Computers and Electronics in Agriculture*, 207, 107707.
- [Arac, A., et al. (2019)](https://doi.org/10.3389/fnsys.2019.00020) DeepBehavior: A Deep Learning Toolbox for Automated Analysis of Animal and Human Behavior Imaging Data. *Frontiers in Systems Neuroscience*, 13, 20.
- [Beltran, R. S. (2024)](https://doi.org/10.1016/j.tree.2024.09.009). Maximizing biological insights from instruments attached to animals. *Trends in Ecology & Evolution*, 40(1), 37–46
- [Bergen, S., et al. (2022)](https://doi.org/10.1111/2041-210X.14019). A review of supervised learning methods for classifying animal behavioural states from environmental features. *Methods in Ecology and Evolution*, 14(1), 189-202.
- [Brewster, L. R., et al. (2021)](https://doi.org/10.3390/s21196392). Classifying Goliath Grouper (*Epinephelus itajara*) behaviours from a novel, multi‑sensor tag. *Sensors*, 21(19), 6392.
- [Cesarani, A., et al. (2021)](https://doi.org/10.3390/ani11030724). Farm animals are long away from natural behavior: open questions and operative consequences on animal welfare. *Animals*, 11(3), 724.
- [Chakravarty, P., et al. (2019)](https://doi.org/10.1111/2041-210X.13172). A novel biomechanical approach for animal behaviour recognition using accelerometers. *Methods in Ecology and Evolution*, 10(6), 802–814.
- [Choi, T., et al., 2022](https://doi.org/10.48550/arXiv.2108.09394). Beyond Tracking: Using Deep Learning to Discover Novel Interactions in Biological Swarms. *Artificial Life and Robotics* 27, 2, 393–400
- [Chung, H., et al. (2021)](https://doi.org/10.1007/s12601-021-00015-1). A review: Marine bio‑logging of animal behaviour and ocean environments. *Ocean Science Journal*, 56(2), 117–131.
- [Dunford, C., et al. (2024)](https://doi.org/10.1002/ece3.11380). Identifying animal behaviours from accelerometers: improving predictive accuracy of machine learning by refining variable selection, data frequency, and sample duration.  *Ecology and Evolution*, 14, e11380.
- [Dupont F., et al. (2025)](https://doi.org/10.1111/2041-210X.70025). Improved order selection method for hidden Markov models: A case study with movement data. *Methods in Ecology and Evolution*, 16(6), 1215-1227.
- [Fazzari, E., et al. (2024)](https://doi.org/10.48550/arXiv.2405.14002). Animal Behavior Analysis Methods Using Deep Learning: A Survey. *Manuscript submitted to ACM*. arXiv:2405.14002.
- [Galvin, J., 2024](https://news.ucsc.edu/2024/10/biologging-research-framework/). How researchers can maximize biological insights using animal‑tracking devices. *UC Santa Cruz News*.
- [Garde, B., et al. (2022)](https://doi.org/10.1111/2041-210X.13804). Ecological inference using data from accelerometers needscareful protocols. *Methods in Ecology and Evolution*, 13, 813–825.
- [Hoffman, B., et al. (2023)](https://doi.org/10.48550/arXiv.2305.10740). A benchmark for computational analysis of animal behavior, using animal‑borne tags. *NeurIPS Datasets and Benchmarks Track*.
- [Holton, M., et al. (2021)](https://doi.org/10.1098/rstb.2020.0229). Animal tag technology keeps coming of age: an engineering perspective. *Philosophical Transactions of the Royal Society B*, 376(1831), 20200229.
- [Hooten, M. B., et al. (2018)](https://doi.org/10.1111/ele.13198). Running on empty: Recharge dynamics from animal movement data. *Ecology Letters*, 22(2), 377-389.
- [Jia Y., et al., 2022](https://doi.org/10.7554/eLife.76218). Selfee, self-supervised features extraction of animal behaviors. *eLife*, 11, e76218.
- [Ketrzynska, D. (2023)](https://stud.epsilon.slu.se/19548/1/Ketrzynska_Daria_231009.pdf). Validation of a cat activity monitor – with a focus on drinking and littering. *Swedish University of Agricultural Sciences (SLU), Department of Clinical Sciences, Uppsala. Master’s thesis in Animal Science*.
- [Ladds, M. A., et al. (2016)](https://doi.org/10.1371/journal.pone.0166898). Seeing it all: evaluating supervised machine learning methods for the classification of diverse otariid behaviours. *PLOS ONE*, 11(12), e0166898.
- [Leos-Barajas, V., et al. (2016)](https://doi.org/10.1111/2041-210X.12657). Analysis of animal accelerometer data using hidden Markov models, 8, 161-173
- [Otsuka, R., et al. (2024)](https://doi.org/10.1111/2041-210X.14294). Exploring deep learning techniques for wild animal behaviour classification using animal-borne accelerometers. *Methods in Ecology and Evolution*, 15, 716–731.
- [Qasem et al., 2012](https://doi.org/10.1371/journal.pone.0031187). Tri-axial dynamic acceleration as a proxy for animal energy expenditure; should we be summing values or calculating the vector? *PLoS ONE*, 7(2), e31187.
- [Qasem et al., 2012](https://doi.org/10.1371/journal.pone.0031187). Tri-axial dynamic acceleration as a proxy for animal energy expenditure; should we be summing values or calculating the vector? *PLoS ONE*, 7(2), e31187.
- [Rahman, A., et al. (2018)](https://doi.org/10.1016/j.inpa.2017.10.001). Cattle behaviour classification from collar, halter, and ear tag sensors. *Information Processing in Agriculture*, 5(2), 219–231.
- [Segalin et al., 2021](https://doi.org/10.7554/eLife.63720). The Mouse Action Recognition System (MARS) software pipeline for automated analysis of social behaviors in mice. *eLife*, 10, e63720
- [Shepard et al., 2008](https://doi.org/10.3354/esr00084). Identification of animal movement patterns using tri-axial accelerometry. *Endangered Species Research*, 10, 47–60.
- [Shepard et al., 2008](https://doi.org/10.3354/esr00084). Identification of animal movement patterns using tri-axial accelerometry. *Endangered Species Research*, 10, 47–60.
- [Torres, L., et al. (2017)](https://doi.org/10.1371/journal.pone.0168513). Classification of animal movement behavior through residence in space and time. *PLOS ONE*, 12(1), e0168513.
- [Wang, K. et al. (2021)](https://doi.org/10.1016/j.compag.2021.106275). Identification and classification for sheep foraging behavior based on acoustic signal and deep learning. *Computers and Electronics in Agriculture*, 187, 106275
- [Wang, L., et al. (2023)](https://doi.org/10.1016/j.compag.2023.107647). Classifying animal behavior from accelerometry data via recurrent neural networks. *Computers and Electronics in Agriculture* 206, 107647
- [Wang, R., et al. (2023)](http://dx.doi.org/10.18494/SAM4521). Deep‑learning‑based multi‑behavior classification of animals for efficient health and welfare monitoring. *Sensors and Materials*, 35(11), 3947–3968.
- [Whitford, M., et al. (2019)](https://doi.org/10.1186/s40317-019-0189-z). An overview of behavioral, physiological, and environmental sensors used in animal biotelemetry and biologging studies. *Animal Biotelemetry*, 7(1), 1–24.
- [Wilson, O., et al. (2025)](https://doi.org/10.1111/1365-2656.70054). Practical guidelines for validation of supervised machinelearning models in accelerometer-based animal behaviour classification. *Journal of Animal Ecology*, 94, 1322–1334.
- [Yu, H., et al. (2021)](https://doi.org/10.1186/s40462-021-00245-x). An evaluation of machine learning classifiers for next‑generation, continuous‑ethogram smart trackers. *Movement Ecology*, 9, 15.
- [Zhou et al., 2022](https://doi.org/10.48550/arXiv.2208.03819). Cross-Skeleton Interaction Graph Aggregation Network for Representation Learning of Mouse Social Behaviour. *IEEE Transactions on Image Processing*. 34, 623-638
